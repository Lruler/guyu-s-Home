---
title: 运维
---

## Doker

为什么需要Doker?

想象一下，假设我有两个前端项目，一个需要的node版本是14，一个需要的node版本是16，那我在一台机器上怎么同时跑这两个项目？

是不是想不出来怎么跑，那我把这两个项目分别丢到两个独立的容器环境中呢？

这就是Doker的意义。

> Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。
>
> Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。
>
> 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。
>
> Docker 的主要用途，目前有三大类。
>
> **（1）提供一次性的环境。**比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。
>
> **（2）提供弹性的云服务。**因为 Docker 容器可以随开随关，很适合动态扩容和缩容。
>
> **（3）组建微服务架构。**通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。

Docker 包含三个基本概念，分别是镜像（Image）、容器（Container）和仓库（Repository）。镜像是 Docker 运行容器的前提，仓库是存放镜像的场所，可见镜像更是Docker的核心。

Docker 镜像可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变



**Docker 把应用程序及其依赖，打包在 image 文件里面。**只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。

image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。

**image 文件生成的容器实例，本身也是一个文件，称为容器文件。**也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。

image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。

这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。

下面通过一个实例（年终项目），演示如何编写 Dockerfile 文件。

```dockerfile
FROM node:latest

# Create app directory
RUN mkdir -p /usr/src/app
WORKDIR /usr/src/app
COPY . /usr/src/app

WORKDIR /usr/src/app/server

#Build server file
RUN yarn config set registry https://registry.npm.taobao.org/ #换源
RUN yarn install 

# Bundle app source
EXPOSE 3000
CMD [ "npm", "start" ]
```

- `FROM node:latest`：该 image 文件继承官方的 node image，冒号表示标签，这里标签是`latest`，即最新版本的 node。
- `mkdir -p /usr/src/app`：在image文件中创造 `/usr/src/app `文件夹
- `COPY .  /usr/src/app`：将当前目录下的所有文件（除了`.dockerignore`排除的路径），都拷贝进入 image 文件的 `/usr/src/app`目录。
- `WORKDIR /usr/src/app`：指定接下来的工作路径为`/usr/src/app`。
- `RUN yarn install`：在`/usr/src/app`目录下，运行`npm install`命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。
- `EXPOSE 3000`：将容器 3000 端口暴露出来， 允许外部连接这个端口。
- `CMD [ "npm", "start" ]`: 容器启动以后，需要手动输入命令`node ./server/index.js`。我们可以把这个命令写在 Dockerfile 里面，这样容器启动以后，这个命令就已经执行了，不用再手动输入了。

## K8s

k8s是一个开源的容器编排平台，可以自动完成在部署、管理和扩展容器化应用过程中涉及的许多手动操作。

+ service服务进程
+ Pod对象
+ cluster集群

# CDN

CDN (全称 Content Delivery Network)，即内容分发网络

构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。`CDN` 的关键技术主要有内容存储和分发技术

简单来讲，`CDN`就是根据用户位置分配最近的资源

于是，用户在上网的时候不用直接访问源站，而是访问离他“最近的”一个 CDN 节点，术语叫**边缘节点**，其实就是缓存了源站内容的代理服务器。如下图：


## CDN（Content Delivery Network）

CDN部署在应用层

**将远处的资源拷贝过来，放到比较近的缓存服务器**

## Nginx

`Nginx` (engine x) 是一个**轻量级、高性能的HTTP**和**反向代理服务器**,同时也是一个**通用代理服务器**(TCP/UDP/IMAP/POP3/SMTP)

简单的说：

- `Nginx`是一个拥有高性能HTTP和反向代理服务器，其特点是`占用内存少`，`并发能力强`，并且在现实中，nginx的并发能力要比在同类型的网页服务器中表现要好
- `Nginx`专为`性能优化`而开发，最重要的要求便是`性能`，且十分注重效率，有报告nginx能支持高达50000个并发连接数

要点

+ 正向代理和反向代理

正向: 比如翻墙

反向: 比如解决跨域问题

+ **负载均衡**：是高可用网络基础架构的关键组件，通常用于将工作**负载分布到多个服务器**来提高网站、应用、数据库或其他服务的性能和可靠性。

如果没有负载均衡，客户端与服务端的操作通常是：**客户端请求服务端，然后服务端去数据库查询数据，将返回的数据带给客户端**：

但随着客户端越来越多，数据，访问量飞速增长，这种情况显然无法满足，我们从上图发现，客户端的请求和相应都是通过服务端的，那么我们加大服务端的量，让多个服务端分担，是不是就能解决这个问题了呢？

但此时对于客户端而言，他去访问这个地址就是固定的，才不会去管那个服务端有时间，你只要给我返回出数据就OK了，所以我们就需要一个“管理者“，将这些服务端找个老大过来，客户端直接找老大，再由老大分配谁处理谁的数据，从而减轻服务端的压力，而这个”老大“就是**反向代理服务器**，而端口号就是这些服务端的工号。

反向代理服务器会把请求平均分配给服务端，这个过程就称之为：**负载均衡**

+ 静态资源(html,css,img等)，动态资源(服务端数据)，动静分离

### **自动化构建**

现在我们已经探索出一套静态资源组织的解决方案。现在探讨一下构建的过程。我们每次构建时大约需要进行这些步骤：

- 拉取远程仓库

- 切换到 XX 分支

- 代码安全检查（非必选）、单元测试等等

- 安装 npm/yarn 依赖

- - 设置 node 版本
  - 设置 npm/yarn 源
  - 安装依赖等

- 执行编译 & 构建

- 产物检查（比如检测打包后 JS 文件 / 图片大小、产物是否安全等，保证产物质量，非必选）

- 人工卡点（非必选，如必须 Leader 审批通过才能继续）

- 打包上传 CDN

- 自动化测试（非必选，e2e）

- 配套剩余其他步骤

- 通知构建完成

这其中，迎面而来的问题有：

- 在什么环境执行构建？
- 如何保证每次构建部署环境相同？
- 由谁触发构建？
- 如何管理前面所述上传 CDN 等密钥（不增加成本、保证安全、保证构建上传可靠性）？
- 如何自动化触发构建 & 自动化执行上述步骤？

> 假如每次都由人工执行，估计发版日就守着编译打包了，而且较为容易引发问题，比如某步骤遗漏或顺序错了。

- 如何提升构建速率？
- 构建完成如何通知研发同学构建完成了？

为了解决上面问题，业界有一些解决方案：

- 保证环境一致性：Docker
- 按流程构建：Jenkins
- 自动化构建触发：Gitlab webhook 通知
- 开始构建通知：依赖账号体系打通+ Gitlab Webhook
- 构建完成通知：依赖账号体系打通

业界的大致实现，一般都为 Jenkins + Docker + GitlabWebHook，比如下面是一些实践：

- 前端项目自动化部署——超详细教程（Jenkins、Github Actions）
- iDeploy-为前端团队构建部署工程化而开发的一个持续交付平台

## Docker & k8s

通过编写docker file生成镜像，然后允许容器

而 k8s 实际上是一个使用 Docker 容器进行编排的系统，主要围绕 pods 进行工作。Pods 是 k8s 生态中最小的调度单位，可以包含一个或多个容器。

简单来说，k8s负责管理编排容器

## 对象存储

**对象存储**，也称为基于对象的存储，是一种数据存储，其中每个数据单元存储为称为对象的离散单元。对象可以是离散单元，类似于pdf，音频，图像或视频文件。这些对象实际上可以是任何类型的数据和任何大小的数据。对象存储中的所有对象都存储在单个平面地址空间中，而没有文件夹层次结构。

与文件类型和块类型存储不同，对象存储支持有助于描述文件的全面元数据。元数据可帮助您理解和分析大型文件，而无需直接处理文件中包含的内容。

### CI/CD

[参考](https://juejin.cn/post/7031042407504281630#comment)

CI 全名是 *Continuous Integration* —— 持续集成；

CD 全名是 *Continuous Delivery* —— 持续交付；



## 部署缓存

[参考链接1](https://www.zhihu.com/question/20790576/answer/32602154)

[参考链接2](https://www.zhihu.com/question/20790576/answer/2193484036)

简要的说一下部署和缓存的相关问题。

假设不用缓存 服务器有html,css,js等各种资源文件，每次访问都要发请求，负载很大。

那第一次优化 就是指定缓存策略

协商缓存和强缓存就此出现

然后光缓存还不行 还要更新 所以一开始是给静态资源文件加版本号

但问题是 比如有十个静态文件，我们只更新了一个，那改版本号会导致其他九个的缓存也失效。

所以，文件的版本应该和他的内容相关，则有

**消息摘要算法 ，对文件求摘要信息，摘要信息与文件内容一一对应，就有了一种可以精确到单个文件粒度的缓存控制依据**

一个大型的项目，静态资源肯定是放在CDN上的，网页中引用的资源也是有着对应路径。

所以如果在一次更新中，同时改了页面结构和样式，也更新了静态资源对应的url地址，那是先上线静态资源还是页面？

显然是都不行，二者不能有时间版本差。 所以 就用 **非覆盖式发布** 来代替 **覆盖式发布**

**上线过程中，先全量部署静态资源，再灰度部署页面**

文件的命名形式可能为 "index.[hash].js" 可以观察vite build后 index.html 中的文件引入格式，这就能使得服务器中会存在多个静态资源文件，所以不会引起错误引用的问题

基于此 差不多就👌了




# 云原生

云原生是一种基于云计算和容器化技术的软件开发和部署模式，旨在提高应用程序的可伸缩性、弹性和可移植性。它是一种新兴的软件开发和部署范式，旨在利用云计算、DevOps 和容器化等技术来构建、部署和管理应用程序，以实现更高效、更可靠和更灵活的软件交付和管理。

云原生应用程序通常使用容器技术（如Docker）来实现应用程序的封装和隔离，并使用容器编排工具（如Kubernetes）来实现应用程序的自动化部署、伸缩和管理。它还强调了微服务架构、不可变基础设施、持续交付和自动化运维等最佳实践，以提高应用程序的可维护性和可靠性。

云原生技术的优点包括更快的部署速度、更高的可伸缩性、更好的资源利用率和更快的故障恢复能力。它还可以降低应用程序的运维成本，并为应用程序的快速迭代提供支持

云计算（Cloud Computing）是一种基于互联网的计算模式，它允许用户通过网络访问可按需提供的共享计算资源（例如服务器、存储、数据库等），而无需在本地拥有和维护这些资源。云计算为用户提供了弹性、可扩展和成本效益的计算资源，使用户能够更加高效地构建、部署和运行应用程序。

DevOps（Development and Operations）是一种软件开发和运维的方法论，旨在通过协作、自动化和持续交付来提高软件交付速度、质量和可靠性。DevOps 将开发和运维团队整合在一起，以实现更加紧密的协作，同时利用自动化工具来加速软件交付和减少错误。DevOps 还重视持续反馈和持续改进，以不断提高软件交付和运维的效率和质量。

云原生、云计算和 DevOps 是密切相关的概念，它们都旨在提高软件交付和运维的效率、质量和可靠性。云原生应用程序使用云计算和容器化技术来实现可伸缩、弹性和可移植的部署，并借助 DevOps 工具和方法来实现自动化交付和运维。

Serverless 是一种云计算架构，它允许开发人员在无需管理底层服务器或基础设施的情况下构建和运行应用程序。在 Serverless 架构中，云服务提供商（如 AWS Lambda、Azure Functions、Google Cloud Functions 等）承担了服务器和基础设施管理的责任，而开发人员只需编写应用程序代码并上传到云平台中运行。这种架构被称为“Serverless”，因为开发人员无需直接管理服务器，而是通过云服务提供商的平台自动分配和扩展计算资源。

在 Serverless 架构中，应用程序以函数（Function）的形式部署和运行，每个函数都是一个独立的代码单元，只有在需要时才会被调用。这种“按需计算”模型可以使应用程序更加灵活、可伸缩和经济高效，因为开发人员只需为实际使用的计算资源付费。

Serverless 架构的优点包括更快的开发速度、更高的弹性和可伸缩性、更低的运维成本以及更好的性能和可靠性。它适用于需要处理突发流量、需要快速迭代和部署的应用程序，如 Web 应用程序、移动应用程序、数据处理、IoT 应用程序等。

SaaS是软件即服务（Software as a Service）的缩写，是一种云计算模式，通过互联网提供软件应用程序，用户可以通过网络访问、使用、维护和支持这些应用程序，而无需自行安装、部署和维护软件。在 SaaS 模式下，软件供应商负责提供和管理应用程序的基础设施、软件代码和数据存储等，用户只需按需订阅、使用和付费，可以随时增减使用量，无需承担硬件和软件维护的成本和风险。

SaaS 提供了一种更加灵活、可伸缩和成本效益的软件交付模式，用户可以更加专注于应用程序的业务逻辑和价值创造，而不是花费大量时间和资源来部署和维护基础设施和软件。SaaS 模式适用于许多不同的应用场景，例如办公自动化、企业资源规划、客户关系管理、销售管理、人力资源管理、电子商务、在线教育、在线娱乐等。常见的 SaaS 应用程序包括 Google Docs、Salesforce、Dropbox、Zoom 等。



# 什么是Serverless

直接翻译的话意思就是无服务，啥叫无服务呢，我们想想我们怎么做基本开发的。

后端开发服务接口然后部署到服务器上，前端在调用接口拿到数据，是吧。

哎，Serverless出现后，即使没有服务器，不懂运维，我们也能部署接口并调用拿到数据

简单的说就是 **没有服务器， 也能部署应用**

然后Serverless 有两种形式

- `BaaS`：全称 **Backend as a Service**，译为后端即服务。
- `FaaS`：全称 **Function as a Service**，译为函数即服务。



Baas指一个服务端应用，比如云数据库，OSS，而事实上这些我们都可以在服务器上搭建，而真是因为有了这些产品，我们才可以绕过服务器，直接使用这些云端应用。

这也是Serverless的第一层概念: **淡化服务，直接接触服务端应用**

anyway，再仔细想想，我们做前端开发想拿到后端数据，是不是要在本地封装fetch request函数，然后一个request对应一个后端的接口服务，那，如果我直接把这个request做成一个云函数呢？

于是，FaaS就出现了，并且带来了Serverless的第二层概念: **淡化服务器，淡化应用，直接接触函数** (轻服务就是以FaaS为架构的)

















